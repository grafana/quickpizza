discovery.docker "all_containers" {
  host = "unix:///var/run/docker.sock"
}

// set expected labels
discovery.relabel "app_containers" {
  // Drop containers with service.type=instrumentation
  rule {
    source_labels = ["__meta_docker_container_label_service_type"]
    regex = "instrumentation"
    action = "drop"
  }
  // Application Observability expects `job` to be `$service.namespace/$service.name`
  // Reads from service.namespace Docker label and container name to build: namespace/service-name
  rule {
    target_label = "job"
    source_labels = [
      "__meta_docker_container_label_service_namespace",
      "__meta_docker_container_name",
    ]
    regex = "([^;]+);/(.*)"
    replacement = "${1}/${2}"
  }
  rule {
    target_label = "instance"
    source_labels = [
      "__meta_docker_container_name",
    ]
    regex = "/(.*)"
    replacement = "${1}"
  }
  rule {
    target_label = "service_namespace"
    source_labels = [
      "__meta_docker_container_label_service_namespace",
    ]
  }
  // the `namespace` label is for visualizing Profiles in Application Observability
  rule {
    target_label = "namespace"
    source_labels = [
      "__meta_docker_container_label_service_namespace",
    ]
  }
  rule {
    target_label = "service_name"
    source_labels = [
      "__meta_docker_container_name",
    ]
    regex = "/(.*)"
    replacement = "${1}"
  }
  rule {
    target_label = "deployment_environment"
    replacement = coalesce(env("DEPLOYMENT_ENVIRONMENT"), "development")
  }
  targets = discovery.docker.all_containers.targets
}

prometheus.exporter.postgres "default" {
  data_source_names  = [coalesce(env("DB_O11Y_CONNECTION"), "postgresql://localhost:5432/notexist")]
}

discovery.relabel "postgres" {
  rule {
    target_label = "job"
    replacement = format("%s/%s", env("SERVICE_NAMESPACE"), env("DB_SERVICE_NAME"))
  }
  rule {
    target_label = "instance"
    replacement = env("DB_SERVICE_NAME")
  }
  rule {
    target_label = "service_namespace"
    replacement = env("SERVICE_NAMESPACE")
  }
  rule {
    target_label = "namespace"
    replacement = env("SERVICE_NAMESPACE")
  }
  rule {
    target_label = "service_name"
    replacement = env("DB_SERVICE_NAME")
  }
  rule {
    target_label = "deployment_environment"
    replacement = coalesce(env("DEPLOYMENT_ENVIRONMENT"), "development")
  }
  targets = prometheus.exporter.postgres.default.targets
}

// Metrics
prometheus.remote_write "local" {
  endpoint {
    // TODO: Replace this with your prometheus-compatible metrics store
    url = env("METRICS_ENDPOINT")
    send_native_histograms = true
  }
}
prometheus.scrape "app_containers" {
  scrape_interval = "10s"
  targets = concat(discovery.relabel.app_containers.output, discovery.relabel.postgres.output)
  forward_to = [prometheus.remote_write.local.receiver]
}

// Logs
loki.write "local" {
  endpoint {
    url = env("LOGS_ENDPOINT")
  }
}
loki.source.docker "app_containers" {
  host       = "unix:///var/run/docker.sock"
  targets    = discovery.relabel.app_containers.output
  forward_to = [loki.write.local.receiver]
}

// Profiling Pull Mode
pyroscope.write "local" {
   endpoint {
       url = env("PROFILES_ENDPOINT")
   }
}
discovery.relabel "app_containers_profiles" {
  // Filter to only scrape port 3333 for profiling.
  // Docker discovery creates separate targets for each exposed port (3333, 3334, 3335).
  // We only keep port 3333 where the HTTP pprof endpoints are available.
  // Ports 3334 and 3335 are gRPC servers without pprof Pull support.
  rule {
    source_labels = ["__meta_docker_port_private"]
    regex         = "3333"
    action        = "keep"
  }
  // https://grafana.com/docs/pyroscope/latest/view-and-analyze-profile-data/line-by-line/
  rule {
    target_label = "service_repository"
    replacement = coalesce(env("QUICKPIZZA_PYROSCOPE_SERVICE_REPOSITORY"), "https://github.com/grafana/quickpizza")
  }
  rule {
    target_label = "service_git_ref"
    replacement = coalesce(env("QUICKPIZZA_PYROSCOPE_SERVICE_GIT_REF"), "refs/heads/main")
  }
  targets = discovery.relabel.app_containers.output
}
pyroscope.scrape "app_containers" {
  // https://grafana.com/docs/pyroscope/latest/configure-client/grafana-alloy/go_pull/
  scrape_interval = "30s"
  targets = discovery.relabel.app_containers_profiles.output
  forward_to = [pyroscope.write.local.receiver]
}


// Receive traces and metrics with OTEL setup
otelcol.receiver.otlp "default" {
  // https://grafana.com/docs/alloy/latest/reference/components/otelcol.receiver.otlp/
  // configures the default grpc endpoint "0.0.0.0:4317"
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  // configures the default http/protobuf endpoint "0.0.0.0:4318"
  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    metrics = [otelcol.processor.resourcedetection.default.input]
    logs    = [otelcol.processor.resourcedetection.default.input]
    traces  = [otelcol.processor.resourcedetection.default.input]
  }
}

otelcol.processor.resourcedetection "default" {
  // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.resourcedetection/
  detectors = ["env", "system"]
  
  system {
    hostname_sources = ["os"]
  }
  
  output {
    metrics = [otelcol.processor.transform.drop_unneeded_resource_attributes.input]
    logs    = [otelcol.processor.transform.drop_unneeded_resource_attributes.input]
    traces  = [otelcol.processor.transform.drop_unneeded_resource_attributes.input]
  }
}

otelcol.processor.transform "drop_unneeded_resource_attributes" {
  // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.transform/
  error_mode = "ignore"
  
  trace_statements {
    context    = "resource"
    statements = [
      "delete_key(attributes, \"os.description\")",
      "delete_key(attributes, \"os.type\")",
      "delete_key(attributes, \"process.command_args\")",
      "delete_key(attributes, \"process.executable.path\")",
      "delete_key(attributes, \"process.pid\")",
      "delete_key(attributes, \"process.runtime.description\")",
      "delete_key(attributes, \"process.runtime.name\")",
      "delete_key(attributes, \"process.runtime.version\")",
    ]
  }

  trace_statements {
    context    = "span"
    statements = [
      // Without this, servicegraph would use physical addresses (e.g., "localhost:3333", "quickpizza-db:5432")
      // instead of logical service names (e.g., "quickpizza", "database")
      "delete_key(attributes, \"server.address\")",
    ]
  }
  
  metric_statements {
    context    = "resource"
    statements = [
      "delete_key(attributes, \"os.description\")",
      "delete_key(attributes, \"os.type\")",
      "delete_key(attributes, \"process.command_args\")",
      "delete_key(attributes, \"process.executable.path\")",
      "delete_key(attributes, \"process.pid\")",
      "delete_key(attributes, \"process.runtime.description\")",
      "delete_key(attributes, \"process.runtime.name\")",
      "delete_key(attributes, \"process.runtime.version\")",
    ]
  }
  
  log_statements {
    context    = "resource"
    statements = [
      "delete_key(attributes, \"os.description\")",
      "delete_key(attributes, \"os.type\")",
      "delete_key(attributes, \"process.command_args\")",
      "delete_key(attributes, \"process.executable.path\")",
      "delete_key(attributes, \"process.pid\")",
      "delete_key(attributes, \"process.runtime.description\")",
      "delete_key(attributes, \"process.runtime.name\")",
      "delete_key(attributes, \"process.runtime.version\")",
    ]
  }
  
  output {
    metrics = [otelcol.processor.transform.add_resource_attributes_as_metric_attributes.input]
    logs    = [otelcol.processor.batch.default.input]
    traces  = [
      // Traces to ServiceGraph metrics
      otelcol.connector.servicegraph.default.input,
      // Traces to SpanMetrics
      otelcol.processor.transform.spanmetrics.input,
      // Traces to OTLP endpoint
      otelcol.processor.batch.default.input,
    ]
  }
}

otelcol.processor.transform "add_resource_attributes_as_metric_attributes" {
  // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.transform/
  error_mode = "ignore"
  
  metric_statements {
    context    = "datapoint"
    statements = [
      "set(attributes[\"service_name\"], resource.attributes[\"service.name\"])",
      "set(attributes[\"service_namespace\"], resource.attributes[\"service.namespace\"])",
      "set(attributes[\"deployment.environment\"], resource.attributes[\"deployment.environment\"])",
      "set(attributes[\"service.version\"], resource.attributes[\"service.version\"])",
    ]
  }
  
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// Traces to span metrics
// https://grafana.com/docs/tempo/latest/metrics-from-traces/span-metrics/span-metrics-alloy/

// Remove all resource attributes except the ones the otelcol.connector.spanmetrics needs.
otelcol.processor.transform "spanmetrics" {
  error_mode = "ignore"

  trace_statements {
    context = "resource"
    statements = [
      // We keep only the "service.name" resource attribute,
      // because it is the only one which otelcol.connector.spanmetrics needs.
      //
      // There is no need to list "span.name", "span.kind", and "status.code"
      // here because they are properties of the span (and not resource attributes):
      // https://github.com/open-telemetry/opentelemetry-proto/blob/v1.0.0/opentelemetry/proto/trace/v1/trace.proto
      `keep_keys(attributes, ["service.name"])`,
    ]
  }
  output {
    traces  = [otelcol.connector.spanmetrics.default.input]
  }
}
otelcol.connector.spanmetrics "default" {
  metrics_flush_interval = "10s"

  histogram {
    // `s` is the unit used by Application Observability
    // https://grafana.com/docs/grafana-cloud/monitor-applications/application-observability/setup/metrics-labels/
    // this creates `traces_span_metrics_duration_seconds` instead of `traces_span_metrics_duration_milliseconds`
    unit = "s"
    // enable `exponential` option to send native histogram metrics
    exponential {
      max_size = 160
    }
    // `explicit` converts to classic histograms
    // explicit { buckets = ["50ms", "100ms", "250ms", "1s", "5s", "10s"]}
  }

  exemplars {
    enabled = true
  }

  output {
    metrics = [otelcol.processor.transform.add_namespace_labels_to_trace_metrics.input]
  }
}

// Traces to servicegraph metrics
// https://grafana.com/docs/tempo/latest/metrics-from-traces/service_graphs/enable-service-graphs/
otelcol.connector.servicegraph "default" {
  metrics_flush_interval = "10s"
  dimensions = ["http.method", "http.target"]
  // TODO:  Enable when Alloy supports `exponential_histogram_max_size`
  // enable `exponential_histogram_max_size` option to send native histogram metrics
  // exponential_histogram_max_size = 16
  output {
    metrics = [otelcol.processor.transform.add_namespace_labels_to_trace_metrics.input]
  }
}

// Add namespace labels to trace-derived metrics (spanmetrics and servicegraph)
otelcol.processor.transform "add_namespace_labels_to_trace_metrics" {
  // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.transform/
  error_mode = "ignore"
  
  metric_statements {
    context = "datapoint"
    statements = [
      "set(attributes[\"service_namespace\"], \"" + env("SERVICE_NAMESPACE") + "\")",
      "set(attributes[\"namespace\"], \"" + env("SERVICE_NAMESPACE") + "\")",
    ]
  }
  
  output {
    metrics = [otelcol.processor.batch.default.input]
  }
}

// Traces to OTLP endpoint and Metrics to Prometheus
otelcol.processor.batch "default" {
  output {
    metrics = [otelcol.exporter.prometheus.local.input]
    logs = []
    traces = [
      otelcol.exporter.otlp.default.input,
    ]
  }
}

otelcol.exporter.prometheus "local" {
  forward_to = [prometheus.remote_write.local.receiver]
}
otelcol.exporter.otlp "default" {
  client {
    // TODO: Replace this with the endpoint for your trace receiver
    endpoint = env("TRACES_ENDPOINT")
    tls {
        insecure             = true
        insecure_skip_verify = true
    }
  }
}

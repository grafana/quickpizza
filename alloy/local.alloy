// discover containers running QuickPizza
discovery.docker "application_containers" {
  host = "unix:///var/run/docker.sock"
  filter {
    name   = "label"
    values = ["service.type=application"]
  }
}

// set expected labels
discovery.relabel "application_containers" {
  rule {
    target_label = "job"
    source_labels = [
      "__meta_docker_container_name",
    ]
    regex = "/(.*)"
    replacement = "quickpizza/${1}"
  }
  rule {
    target_label = "instance"
    source_labels = [
      "__meta_docker_container_name",
    ]
    regex = "/(.*)"
    replacement = "${1}"
  }
  rule {
    target_label = "service_namespace"
    replacement = "quickpizza"
  }
  // the `namespace` label is for visualizing Profiles in Application Observability
  rule {
    target_label = "namespace"
    replacement = "quickpizza"
  }
  rule {
    target_label = "service_name"
    source_labels = [
      "__meta_docker_container_name",
    ]
    regex = "/(.*)"
    replacement = "${1}"
  }
  targets = discovery.docker.application_containers.targets
}

// Metrics
prometheus.remote_write "local" {
  endpoint {
    // TODO: Replace this with your prometheus-compatible metrics store
    url = env("METRICS_ENDPOINT")
  }
}
prometheus.scrape "application_containers" {
  scrape_interval = "10s"
  targets = discovery.relabel.application_containers.output
  forward_to = [prometheus.remote_write.local.receiver]
}

// Logs
loki.write "local" {
  endpoint {
    url = env("LOGS_ENDPOINT")
  }
}
loki.source.docker "application_containers" {
  host       = "unix:///var/run/docker.sock"
  targets    = discovery.relabel.application_containers.output
  forward_to = [loki.write.local.receiver]
}

// Profiling Pull Mode
pyroscope.write "local" {
   endpoint {
       url = env("PROFILES_ENDPOINT")
   }
}
pyroscope.scrape "application_containers" {
  // https://grafana.com/docs/pyroscope/latest/configure-client/grafana-alloy/go_pull/
  scrape_interval = "30s"
  targets = discovery.relabel.application_containers.output
  forward_to = [pyroscope.write.local.receiver]
}


// Receive traces
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    traces  = [
               // OTLP endpoint
               otelcol.processor.batch.default.input,
               // ServiceGraph
               otelcol.connector.servicegraph.default.input,
               // SpamMetrics
               otelcol.processor.transform.spanmetrics.input,
               ]
  }
}

// Traces to OTLP endpoint
otelcol.processor.batch "default" {
  output {
    metrics = []
    logs = []
    traces = [
      otelcol.exporter.otlp.default.input,
    ]
  }
}
otelcol.exporter.otlp "default" {
  client {
    // TODO: Replace this with the endpoint for your trace receiver
    endpoint = env("TRACES_ENDPOINT")
    tls {
        insecure             = true
        insecure_skip_verify = true
    }
  }
}

// Traces to spanmetrics
otelcol.processor.transform "spanmetrics" {
  error_mode = "ignore"

  trace_statements {
    context = "resource"
    statements = [
      // We keep only the "service.name" and "special.attr" resource attributes,
      // because they are the only ones which otelcol.connector.spanmetrics needs.
      //
      // There is no need to list "span.name", "span.kind", and "status.code"
      // here because they are properties of the span (and not resource attributes):
      // https://github.com/open-telemetry/opentelemetry-proto/blob/v1.0.0/opentelemetry/proto/trace/v1/trace.proto
      `keep_keys(attributes, ["service.name", "special.attr"])`,
    ]
  }

  output {
    traces  = [otelcol.connector.spanmetrics.default.input]
  }
}

otelcol.connector.spanmetrics "default" {
  metrics_flush_interval = "10s"
  histogram {
    explicit {}
  }
  dimension {
    name = "special.attr"
  }
  output {
    metrics = [otelcol.exporter.prometheus.local.input]
  }
}

// Traces to servicegraph metrics
// https://grafana.com/docs/tempo/latest/metrics-from-traces/service_graphs/enable-service-graphs/
otelcol.connector.servicegraph "default" {
  metrics_flush_interval = "10s"
  dimensions = ["http.method", "http.target"]
  output {
    metrics = [otelcol.exporter.prometheus.local.input]
  }
}

otelcol.exporter.prometheus "local" {
  forward_to = [prometheus.remote_write.local.receiver]
}